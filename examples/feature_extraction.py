"""
Script for computing internal features
using an aluminum model generated by the user.
For training the example model, see `ani_aluminum_example.py`.
That script will generate the files for a model.

"""
import torch

if torch.cuda.is_available():
    device = torch.device(0)
else:
    device = torch.device("cpu")
import hippynn

### Load the model
with hippynn.tools.active_directory("./TEST_ALUMINUM_MODEL", create=False):
    model = hippynn.experiment.serialization.load_model_from_cwd(map_location=device)

network_node = model.node_from_name("HIPNN")  # This name was defined in the training script

### Get the feature nodes
# Here we get nodes associated with the features from each block of a HIP-NN model.
# Note: the first set is typically just a one-hot species representation, and does not reflect the atom's environment.

feature_nodes = network_node.feature_nodes  # list of feature nodes
feature_node_dict = {node.name: node for node in feature_nodes}  # dictionary of feature nodes

### How to use feature nodes with ASE
# The key thing is to include the nodes in the `extra_properties` dictionary.
# Afterwards, the features will be included in the `results` dictionary.
from hippynn.interfaces.ase_interface import HippynnCalculator
import ase.build
from ase import units

energy_node = model.node_from_name("energy")
calc = HippynnCalculator(energy_node, en_unit=units.eV, extra_properties=feature_node_dict)
calc.to(device)

# Setup example system
atoms = ase.build.bulk("Al", crystalstructure="fcc", a=4.05)
reps = [[2, 0, 0], [0, 2, 0], [0, 0, 1]]
atoms = ase.build.make_supercell(atoms, reps, wrap=True)
atoms.rattle(0.1, seed=0)
atoms.calc = calc

# Trigger calculation
atoms.get_potential_energy()
# Extract features from calculator results dictionary.
results = atoms.calc.results
feature_results = {name: results[name] for name in feature_node_dict}
print("Features calculated:")
for k, v in feature_results.items():
    print(k, ":")
    print(v)

### How to use feature nodes with a predictor object
# The key here is to use the `additional_outputs` dictionary.

predictor = hippynn.graphs.Predictor.from_graph(model, additional_outputs=feature_node_dict, model_device=device)

# The predictor can then be used as usual on, e.g., some pytorch tensors or a database.
# For more examples see https://lanl.github.io/hippynn/examples/predictor.html

import sys

sys.path.append("../../datasets/ani-al/readers/lib/")
import pyanitools  # Check if pyanitools is found early
from hippynn.databases.h5_pyanitools import PyAniDirectoryDB

inputs = [x.db_name for x in model.input_nodes]  # get the db_names of the inputs the model needs.

database = PyAniDirectoryDB(
    directory="../../datasets/ani-al/data/",
    seed=1001,  # Random seed for splitting data
    quiet=True,
    inputs=inputs,
    targets=[],
)

database.split_the_rest("all_data")  # make a split for all the data.

# Apply the predictor object to the database.
outputs = predictor.apply_to_database(database, batch_size=64)
outputs = outputs["all_data"]  # When a predictor is applied to a database, the outputs are given per-split.

print("Result tensor information:")
for k in feature_node_dict:
    result = outputs[k]
    print(k, type(result), result.shape, result.dtype)
