#!/usr/bin/env python3
# fmt: off
#SBATCH --time=4-00:00:00
#SBATCH --nodes=1
#SBATCH --mail-type=all
#SBATCH -p gpu 
#SBATCH -J parallel_hyperopt
#SBATCH --qos=long
#SBATCH -o run.log
# black always format pure comments as of now
# add some codes here to keep SLURM derivatives valid
import json
import os
import sys
import warnings

# SLURM copies the script to a tmp folder
# so to find the local package `training` we need add cwd to path
# per https://stackoverflow.com/a/39574373/7066315
sys.path.append(os.getcwd())
# fmt: on
"""
    Hyperparameter tuning for HIPNN using AX and Ray.

    Developed by Xinyang Li (LANL) based on the Ax script.
"""

import shutil

import numpy as np
import ray
from ax.core import Trial as AXTrial
from ax.service.ax_client import AxClient
from ax.service.utils.instantiation import ObjectiveProperties
from QM7_ax_example import training
from ray import air, tune
from ray.air import session
from ray.tune.experiment.trial import Trial
from ray.tune.logger import JsonLoggerCallback, LoggerCallback
from ray.tune.search import ConcurrencyLimiter
from ray.tune.search.ax import AxSearch

# to make sure ray loads correct the local package
ray.init(runtime_env={"working_dir": "."})


def evaluate(parameters: dict, checkpoint_dir=None):
    """
    Evaluate a trial for QM7

    Args:
        parameter (dict): Python dictionary for trial values of HIPNN hyperparameters.
        checkpoint_dir (str, optional): To enable checkpoints for ray. Defaults to None.

    Returns:
        dict : Loss metrics to be minimized.
    """

    out = training(**parameters)

    session.report({"Metric": out["valid"]["Loss"]})


class AxLogger(LoggerCallback):
    def __init__(self, ax_client: AxClient, json_name: str, csv_name: str):
        """
        A logger callback to save the progress to json file after every trial ends.
        Similar to running `ax_client.save_to_json_file` every iteration in sequential
        searches.

        Args:
            ax_client (AxClient): ax client to save
            json_name (str): name for the json file. Append a path if you want to save the \
                json file to somewhere other than cwd.
            csv_name (str): name for the csv file. Append a path if you want to save the \
                csv file to somewhere other than cwd.
        """
        self.ax_client = ax_client
        self.json = json_name
        self.csv = csv_name

    def log_trial_end(
        self, trial: Trial, id: int, metric: float, runtime: int, failed: bool = False
    ):
        self.ax_client.save_to_json_file(filepath=self.json)
        shutil.copy(self.json, f"{trial.local_dir}/{self.json}")
        try:
            data_frame = self.ax_client.get_trials_data_frame().sort_values("Metric")
            data_frame.to_csv(self.csv, header=True)
        except KeyError:
            pass
        shutil.copy(self.csv, f"{trial.local_dir}/{self.csv}")
        if failed:
            status = "failed"
        else:
            status = "finished"
        print(
            f"AX trial {id} {status}. Final loss: {metric}. Time taken"
            f" {runtime} seconds. Location directory: {trial.local_path}."
        )

    def on_trial_error(self, iteration: int, trials: list[Trial], trial: Trial, **info):
        id = int(trial.experiment_tag.split("_")[0]) - 1
        ax_trial = self.ax_client.get_trial(id)
        ax_trial.mark_abandoned(reason="Error encountered")
        self.log_trial_end(
            trial, id + 1, "not available", self.calculate_runtime(ax_trial), True
        )

    def on_trial_complete(
        self, iteration: int, trials: list["Trial"], trial: Trial, **info
    ):
        # trial.trial_id is the random id generated by ray, not ax
        # the default experiment_tag starts with ax' trial index
        # but this workaround is totally fragile, as users can
        # customize the tag or folder name
        id = int(trial.experiment_tag.split("_")[0]) - 1
        ax_trial = self.ax_client.get_trial(id)
        failed = False
        try:
            loss = ax_trial.objective_mean
        except ValueError:
            failed = True
            loss = "not available"
        else:
            if np.isnan(loss) or np.isinf(loss):
                failed = True
                loss = "not available"
        if failed:
            ax_trial.mark_failed()
        self.log_trial_end(
            trial, id + 1, loss, self.calculate_runtime(ax_trial), failed
        )

    @classmethod
    def calculate_runtime(cls, trial: AXTrial):
        delta = trial.time_completed - trial.time_run_started
        return int(delta.total_seconds())


# initialize the client and experiment.
if __name__ == "__main__":

    warnings.warn(
        "\nMake sure to modify the dataset path in QM7_ax_example.py before running this example.\n"
        "For this test (Ray parallelized optimization), you MUST provide an absolute path to the dataset."
    )

    if len(sys.argv) == 2:
        with open(sys.argv[1], "r") as param:
            parameters = json.load(param)
    else:
        parameters = [
            {
                "name": "dist_soft_min",
                "type": "range",
                "value_type": "float",
                "bounds": [0.5, 1.5],
            },
            {
                "name": "dist_soft_max",
                "type": "range",
                "value_type": "float",
                "bounds": [3.0, 20.0],
            },
            {
                "name": "dist_hard_max",
                "type": "range",
                "value_type": "float",
                "bounds": [5.0, 40.0],
            },
        ]
    # TODO: better way to handle restarting of searches
    restart = False
    if restart:
        ax_client = AxClient.load_from_json_file(filepath="hyperopt_ray.json")
        # update existing experiment
        # `immutable_search_space_and_opt_config` has to be False
        # when the experiment was created
        ax_client.set_search_space(parameters)
    else:
        ax_client = AxClient(
            verbose_logging=False,
            enforce_sequential_optimization=False,
        )
        ax_client.create_experiment(
            name="QM7_ray_opt",
            parameters=parameters,
            objectives={
                "Metric": ObjectiveProperties(minimize=True),
            },
            overwrite_existing_experiment=True,
            is_test=False,
            # slightly more overhead
            # but make it possible to adjust the experiment setups
            immutable_search_space_and_opt_config=False,
            parameter_constraints=[
                "dist_soft_min <= dist_soft_max",
                "dist_soft_max <= dist_hard_max",
            ],
        )

    # run the optimization Loop.
    algo = AxSearch(ax_client=ax_client)
    algo = ConcurrencyLimiter(algo, max_concurrent=4)
    ax_logger = AxLogger(ax_client, "hyperopt_ray.json", "hyperopt.csv")
    tuner = tune.Tuner(
        tune.with_resources(evaluate, resources={"gpu": 1}),
        tune_config=tune.TuneConfig(search_alg=algo, num_samples=8),
        run_config=air.RunConfig(
            local_dir="test_ray",
            verbose=0,
            callbacks=[ax_logger, JsonLoggerCallback()],
            log_to_file=True,
        ),
    )
    tuner.fit()
